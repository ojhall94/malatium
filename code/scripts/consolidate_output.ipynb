{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate Output\n",
    "This program reads in the data from runs on the BlueBEAR cluster via RDS and appends them on to the existing `malatium` and `copper` dataframes, saving them as `atium` and `bronze` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we flagging?\n",
    "\n",
    "We want to flag:\n",
    "- Poor convergence in the splitting and inclination values\n",
    "- Rhat values\n",
    "- The effective n percentage\n",
    "- The location on the HR diagram\n",
    " - MS: log(g) > 4.2 and Teff < 6250\n",
    " - SG: log(g) < 4.2\n",
    " - H: log(g) > 4.2 and Teff > 6250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "import pandas as pd\n",
    "import fnmatch as fnm\n",
    "import seaborn as sns\n",
    "import astropy.units as u\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['KIC','Teff','age','dnu','eTeff','ednu','efeh','enumax','feh','loage','lomodlogg','lomodmass','lomodrad','modlogg','modmass','modrad','numax','source','upage','upmodlogg', 'upmodmass','upmodrad','G','bprp']\n",
    "mal = pd.read_csv('../../data/malatium.csv', usecols=cols)\n",
    "cop = pd.read_csv('../../data/copper.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal['hrclass'] = ''\n",
    "s = np.where((mal.modlogg > 4.2) & (mal.Teff < 6250))[0]\n",
    "mal.loc[s, 'hrclass'] = 'MS'\n",
    "s = np.where((mal.modlogg < 4.2))[0]\n",
    "mal.loc[s, 'hrclass'] = 'SG'\n",
    "s = np.where((mal.modlogg > 4.2) & (mal.Teff > 6250))[0]\n",
    "mal.loc[s, 'hrclass'] = 'H'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the mode results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse all the data, including some flags:\n",
    "\n",
    "`empty   : run not yet done`\n",
    "\n",
    "`rhat_1  : has at least one rhat > 1.1. Major concern, exclude from sample`\n",
    "\n",
    "`nosum   : there is no summary available for some reason`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop['f'] = np.nan\n",
    "cop['f_e'] = np.nan\n",
    "cop['g'] = np.nan\n",
    "cop['g_e'] = np.nan\n",
    "cop['A'] = np.nan\n",
    "cop['A_e'] = np.nan\n",
    "cop['H'] = np.nan\n",
    "cop['H_e'] = np.nan\n",
    "cop['flag'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 70/95 [00:37<00:08,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhats greater than 1.1 for KIC 4143755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:46<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 stars yet to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "incomplete = 0\n",
    "for idx in tqdm(range(95)):\n",
    "    kic = str(mal.loc[idx].KIC)\n",
    "    files = glob.glob('/home/oliver/PhD/mnt/RDS/malatium/peakbag/{}/*chains.csv'.format(str(kic)))\n",
    "\n",
    "    try:\n",
    "        chains = pd.read_csv(files[0],index_col=0)\n",
    "        lis = list(chains)\n",
    "    except IndexError:\n",
    "        incomplete += 1\n",
    "        cop.loc[cop.KIC == kic, 'flag'] = 'empty'\n",
    "        continue\n",
    "\n",
    "    # Lets do each mode in turn\n",
    "    for mode in [0,1,2]:\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'f'] = np.median(chains[fnm.filter(lis, f'f{mode}_*')], axis=0)\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'f_e'] = np.std(chains[fnm.filter(lis, f'f{mode}_*')], axis=0).values\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'g'] = np.median(chains[fnm.filter(lis, f'g{mode}_*')], axis=0)\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'g_e'] = np.std(chains[fnm.filter(lis, f'g{mode}_*')], axis=0).values\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'A'] = np.median(chains[fnm.filter(lis, f'a{mode}_*')], axis=0)\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'A_e'] = np.std(chains[fnm.filter(lis, f'a{mode}_*')], axis=0).values\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'H'] = np.median(chains[fnm.filter(lis, f'h{mode}_*')], axis=0)\n",
    "        cop.loc[(cop.KIC==kic)&(cop.l==mode),'H_e'] = np.std(chains[fnm.filter(lis, f'h{mode}_*')], axis=0).values    \n",
    "    \n",
    "    #Lets copy over the Rhats for each mode and flag if needed\n",
    "    try:\n",
    "        summary = pd.read_csv(files[0].replace('chains','summary'), index_col=0)\n",
    "        rhats = summary.loc[fnm.filter(lis, '*__*')].Rhat.values\n",
    "        \n",
    "        if any(np.abs(rhats - 1.) >= 0.1):\n",
    "            print('Rhats greater than 1.1 for KIC {}'.format(str(kic)))\n",
    "            cop.loc[cop.KIC==kic, 'flag'] = 'rhat_1'\n",
    "\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print('No summary file for KIC {}'.format(str(kic)))\n",
    "        mal.loc[idx, 'flag'] = 'nosum'\n",
    "        pass\n",
    "print(f'There are {incomplete} stars yet to run.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop.to_csv('../../data/bronze.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the parameters results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the necessary columns to malatium\n",
    "mal['nus*'] = np.nan\n",
    "mal['l_nus*'] = np.nan\n",
    "mal['u_nus*'] = np.nan\n",
    "\n",
    "mal['cosi'] = np.nan\n",
    "mal['l_cosi'] = np.nan\n",
    "mal['u_cosi'] = np.nan\n",
    "\n",
    "mal['i'] = np.nan\n",
    "mal['l_i'] = np.nan\n",
    "mal['u_i'] = np.nan\n",
    "\n",
    "mal['nus'] = np.nan\n",
    "mal['l_nus'] = np.nan\n",
    "mal['u_nus'] = np.nan\n",
    "\n",
    "mal['P'] = np.nan\n",
    "mal['l_P'] = np.nan\n",
    "mal['u_P'] = np.nan\n",
    "\n",
    "mal['vsini'] = np.nan\n",
    "mal['l_vsini'] = np.nan\n",
    "mal['u_vsini'] = np.nan\n",
    "\n",
    "mal['fit_numax'] = np.nan\n",
    "mal['efit_numax'] = np.nan\n",
    "mal['fit_d01'] = np.nan\n",
    "mal['efit_d01'] = np.nan\n",
    "mal['fit_d02'] = np.nan\n",
    "mal['efit_d02'] = np.nan\n",
    "mal['fit_epsilon'] = np.nan\n",
    "mal['efit_epsilon'] = np.nan\n",
    "\n",
    "mal['V1'] = np.nan\n",
    "mal['eV1'] = np.nan\n",
    "\n",
    "mal['V2'] = np.nan\n",
    "mal['eV2'] = np.nan\n",
    "\n",
    "mal['rhat_flag'] = ''\n",
    "mal['corner_flag'] = np.nan\n",
    "mal['neff_xsplit'] = np.nan\n",
    "mal['neff_cosi'] = np.nan\n",
    "mal['neff_split'] = np.nan\n",
    "mal['neff_i'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 13/95 [00:05<00:40,  2.01it/s]"
     ]
    }
   ],
   "source": [
    "incomplete = 0\n",
    "for idx in tqdm(range(95)):\n",
    "    kic = mal.loc[idx].KIC\n",
    "    files = glob.glob('/home/oliver/PhD/mnt/RDS/malatium/peakbag/{}/*chains.csv'.format(str(kic)))\n",
    "\n",
    "    # Check to see if run is done\n",
    "    try:\n",
    "        chains = pd.read_csv(files[0],index_col=0)\n",
    "        niters = len(chains)\n",
    "    except IndexError:\n",
    "        incomplete += 1\n",
    "        mal.loc[idx, 'rhat_flag'] = 'empty'\n",
    "        continue\n",
    "\n",
    "    #Flag Rhat values & Neff values\n",
    "    try:\n",
    "        summary = pd.read_csv(files[0].replace('chains','summary'), index_col=0)\n",
    "        rhats = summary.loc[['xsplit','cosi','i','split']].Rhat.values\n",
    "        \n",
    "        if any(np.abs(rhats - 1.) >= 0.01):\n",
    "            print('Rhats greater than 1.01 for KIC {}'.format(str(kic)))\n",
    "            mal.loc[idx, 'rhat_flag'] = 'rhat_01'  \n",
    "        \n",
    "        if any(np.abs(rhats - 1.) >= 0.1):\n",
    "            print('Rhats greater than 1.1 for KIC {}'.format(str(kic)))\n",
    "            mal.loc[idx, 'rhat_flag'] = 'rhat_1'\n",
    "\n",
    "        neff = summary.loc[['xsplit','cosi','i','split']].n_eff\n",
    "        mal.loc[idx, 'neff_xsplit'] = int(neff['xsplit'])\n",
    "        mal.loc[idx, 'neff_cosi'] = int(neff['cosi'])\n",
    "        mal.loc[idx, 'neff_split'] = int(neff['split'])\n",
    "        mal.loc[idx, 'neff_i'] = int(neff['i'])\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        mal.loc[idx, 'flag'] = 'nosum'\n",
    "        pass\n",
    "    \n",
    "    l, m, up = np.percentile(chains['xsplit'].values,[15.9, 50, 84.1])\n",
    "    mal.loc[idx, 'l_nus*'], mal.loc[idx, 'nus*'], mal.loc[idx, 'u_nus*'] = m-l, m, up-m\n",
    "    \n",
    "    l, m, up = np.percentile(chains['cosi'].values, [15.9, 50, 84.1])\n",
    "    mal.loc[idx, 'l_cosi'], mal.loc[idx, 'cosi'], mal.loc[idx, 'u_cosi'] = m-l, m, up-m\n",
    "    \n",
    "    l, m, up = np.percentile(chains['split'].values,[15.9, 50, 84.1])\n",
    "    mal.loc[idx, 'l_nus'], mal.loc[idx, 'nus'], mal.loc[idx, 'u_nus'] = m-l, m, up-m\n",
    "    \n",
    "    l, m, up = np.percentile(chains['i'].values, [15.9, 50, 84.1])    \n",
    "    mal.loc[idx, 'l_i'], mal.loc[idx, 'i'], mal.loc[idx, 'u_i'] =  m-l, m, up-m\n",
    "    \n",
    "    m, up = np.percentile(chains['numax'].values, [50, 84.1])    \n",
    "    mal.loc[idx, 'fit_numax'], mal.loc[idx, 'efit_numax'] =  m, up-m\n",
    "\n",
    "    m, up = np.percentile(chains['d01'].values, [50, 84.1])    \n",
    "    mal.loc[idx, 'fit_d01'], mal.loc[idx, 'efit_d01'] =  m, up-m\n",
    "    \n",
    "    m, up = np.percentile(chains['d02'].values, [50, 84.1])    \n",
    "    mal.loc[idx, 'fit_d02'], mal.loc[idx, 'efit_d02'] =  m, up-m\n",
    "    \n",
    "    m, up = np.percentile(chains['epsilon'].values, [50, 84.1])    \n",
    "    mal.loc[idx, 'fit_epsilon'], mal.loc[idx, 'efit_epsilon'] =  m, up-m\n",
    "    \n",
    "    m, up = np.percentile(chains['V1'].values, [50, 84.1])    \n",
    "    mal.loc[idx, 'V1'], mal.loc[idx, 'eV1'] =  m, up-m\n",
    "    \n",
    "    m, up = np.percentile(chains['V2'].values, [50, 84.1])    \n",
    "    mal.loc[idx, 'V2'], mal.loc[idx, 'eV2'] =  m, up-m    \n",
    "    \n",
    "    nus = u.Quantity(chains['split'].values, u.microhertz)\n",
    "    Pchain = 1./nus.to(1./u.day).value\n",
    "    l, m, up = np.percentile(Pchain, [15.9, 50, 84.1])  \n",
    "    mal.loc[idx, 'l_P'], mal.loc[idx, 'P'], mal.loc[idx, 'u_P'] = m-l, m, up-m\n",
    "    \n",
    "    Rkm = u.Quantity(mal.loc[idx, 'modrad'], u.solRad).to(u.km)\n",
    "    vsinichain = np.sin(chains['i'].values) * 2 * np.pi * Rkm / (1./nus.to(u.Hertz).value)\n",
    "    l, m, up = np.percentile(vsinichain, [15.9, 50, 84.1])  \n",
    "    mal.loc[idx, 'l_vsini'], mal.loc[idx, 'vsini'], mal.loc[idx, 'u_vsini'] = m-l, m, up-m\n",
    "    \n",
    "print(f'There are {incomplete} stars still to run.') \n",
    "print(f\"Of these, {len(np.where((mal.rhat_flag == 'empty') & (mal.hrclass == 'MS'))[0])} lie in the MS region.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally I'm going to calculate the BP-RP errors.\n",
    "SQL is broken and I can't add this script to get_data.ipynb, so I'm doing it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "gkf = Table.read('../../data/kepler_dr2_1arcsec.fits', format='fits').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = Table.read('../../data/kepler_dr2_1arcsec.fits', format='fits').to_pandas().rename(columns={\n",
    "                    'kepid':'KIC'})[['KIC','phot_bp_mean_flux',\n",
    "                                     'phot_bp_mean_flux_error',\n",
    "                                     'phot_rp_mean_flux',\n",
    "                                     'phot_rp_mean_flux_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebp = gkf['phot_bp_mean_flux_error'] / (gkf['phot_bp_mean_flux']) * np.log(10)\n",
    "erp = gkf['phot_rp_mean_flux_error'] / (gkf['phot_rp_mean_flux']) * np.log(10)\n",
    "gkf['ebprp'] = np.sqrt(ebp**2 + erp**2)\n",
    "mal = pd.merge(mal, gkf[['KIC','ebprp']], on='KIC', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal.to_csv('../../data/atium.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mal.loc[mal.hrclass == 'MS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal.loc[mal.hrclass == 'MS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By-Eye investigations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to add flags based on by-eye inspection of the corner plots as well.\n",
    "\n",
    "`-1 : no data`\n",
    "\n",
    "`0   : no issues`\n",
    "\n",
    "`1 : poorly constrained rotational parameters`\n",
    "\n",
    "`2  : bimodal distributions`\n",
    "\n",
    "`3   : divergence/poor sampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "choice = input('Are we going to investigate the corners? (y/n) ')\n",
    "\n",
    "if choice == 'y':\n",
    "    for idx in range(95):\n",
    "        kic = mal.loc[idx].KIC\n",
    "        files = glob.glob('/home/oliver/PhD/mnt/RDS/malatium/peakbag/{}/*chains.csv'.format(str(kic)))\n",
    "\n",
    "        try:\n",
    "            \n",
    "            chains = pd.read_csv(files[0],index_col=0)\n",
    "        except IndexError:\n",
    "            print('Star {} has not completed yet | idx {}'.format(str(kic), idx))\n",
    "            mal.loc[idx, 'flagch'] = -1\n",
    "            continue\n",
    "            \n",
    "        labels=['xsplit','cosi','i','split']\n",
    "        chain = np.array([chains[label] for label in labels])\n",
    "        \n",
    "        corner.corner(chain.T, labels=labels, quantiles=[0.16, 0.5, 0.84]\n",
    "                      ,show_titles=True)\n",
    "        plt.show()\n",
    "        \n",
    "        print('KIC {}\\n\\\n",
    "              0   : no issues \\n\\\n",
    "              1 : poorly constrained rotational parameters\\n\\\n",
    "              2  : bimodal distributions\\n\\\n",
    "              3   : not converged'.format(str(kic)))\n",
    "        flag = int(input('Flag: '))\n",
    "        mal.loc[idx, 'chainflag'] = flag\n",
    "        \n",
    "else:\n",
    "    mal['chainflag'] = pd.read_csv('../../data/atium.csv',usecols=['chainflag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally I'm going to calculate the BP-RP errors.\n",
    "SQL is broken and I can't add this script to get_data.ipynb, so I'm doing it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "gkf = Table.read('../../data/kepler_dr2_1arcsec.fits', format='fits').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = Table.read('../../data/kepler_dr2_1arcsec.fits', format='fits').to_pandas().rename(columns={\n",
    "                    'kepid':'KIC'})[['KIC','phot_bp_mean_flux',\n",
    "                                     'phot_bp_mean_flux_error',\n",
    "                                     'phot_rp_mean_flux',\n",
    "                                     'phot_rp_mean_flux_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebp = gkf['phot_bp_mean_flux_error'] / (gkf['phot_bp_mean_flux']) * np.log(10)\n",
    "erp = gkf['phot_rp_mean_flux_error'] / (gkf['phot_rp_mean_flux']) * np.log(10)\n",
    "gkf['ebprp'] = np.sqrt(ebp**2 + erp**2)\n",
    "mal = pd.merge(mal, gkf[['KIC','ebprp']], on='KIC', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal.to_csv('../../data/atium.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
